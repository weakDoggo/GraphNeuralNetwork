{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-03 18:37:45.217339: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-03 18:37:45.865673: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-08-03 18:37:45.865696: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-08-03 18:37:47.677003: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-08-03 18:37:47.677182: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-08-03 18:37:47.677192: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/home/olga/.local/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import json\n",
    "import gridSearch as g\n",
    "import math\n",
    "import batching as b\n",
    "import modularized as m\n",
    "import convL\n",
    "import convo as c\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import gridS\n",
    "import funcy as fy\n",
    "import gin\n",
    "import poolingL\n",
    "from ogb.nodeproppred import NodePropPredDataset\n",
    "from ogb.graphproppred import GraphPropPredDataset\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import experiments as e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset1 = GraphPropPredDataset(name = 'ogbg-molhiv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_arxiv = NodePropPredDataset(name='ogbn-arxiv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'activation': 'relu',\n",
       "  'convo_type': 'gin',\n",
       "  'learning_rate': 0.0001,\n",
       "  'num_layers': 1,\n",
       "  'optimizer': 'Adam',\n",
       "  'probability': 0.3,\n",
       "  'regularization': 'DropOut',\n",
       "  'units': 32},\n",
       " {'activation': 'relu',\n",
       "  'convo_type': 'gin',\n",
       "  'learning_rate': 0.0001,\n",
       "  'num_layers': 1,\n",
       "  'optimizer': 'Adam',\n",
       "  'probability': 0.3,\n",
       "  'regularization': 'DropOut',\n",
       "  'units': 64},\n",
       " {'activation': 'relu',\n",
       "  'convo_type': 'gin',\n",
       "  'learning_rate': 0.0001,\n",
       "  'num_layers': 1,\n",
       "  'optimizer': 'Adam',\n",
       "  'probability': 0.3,\n",
       "  'regularization': 'NodeSampling',\n",
       "  'units': 32}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'num_layers': [1, 2, 3, 4, 5, 6],\n",
    "              'learning_rate': [0.0001, 0.001, 0.01],\n",
    "              'optimizer': ['Adam'],\n",
    "              'regularization': ['DropOut', 'NodeSampling', 'DropEdge', 'GDC'],\n",
    "              'probability': [0.3, 0.5, 0.7],\n",
    "              'activation': ['relu', 'sigmoid', 'tanh'],\n",
    "              'units': [32, 64],\n",
    "              'convo_type': ['gcn', 'gin']}\n",
    "\n",
    "override_conv_type = 'gin'  # None\n",
    "\n",
    "if override_conv_type is not None:\n",
    "    param_grid['convo_type'] = [override_conv_type]\n",
    "\n",
    "small_sample = list(ParameterGrid(param_grid))[0:3]\n",
    "sample = list(ParameterGrid(param_grid))[0:5]\n",
    "big_sample = list(ParameterGrid(param_grid))[0:20]\n",
    "small_sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = GraphPropPredDataset('ogbg-molhiv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-03 18:38:13.631870: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-08-03 18:38:13.632411: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-08-03 18:38:13.632447: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (DESKTOP-UCI9MJD): /proc/driver/nvidia/version does not exist\n",
      "2023-08-03 18:38:13.633686: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating hyperparameter configuration 0 for dataset ogbg-molhiv.\n",
      "Repeat 0 for hyperparameter configuration 0 already evaluated for dataset ogbg-molhiv.\n",
      "Repeat 1 for hyperparameter configuration 0 already evaluated for dataset ogbg-molhiv.\n",
      "Repeat 2 for hyperparameter configuration 0 already evaluated for dataset ogbg-molhiv.\n",
      "Evaluating hyperparameter configuration 1 for dataset ogbg-molhiv.\n",
      "Repeat 0 for hyperparameter configuration 1 already evaluated for dataset ogbg-molhiv.\n",
      "Repeat 1 for hyperparameter configuration 1 already evaluated for dataset ogbg-molhiv.\n",
      "Repeat 2 for hyperparameter configuration 1 already evaluated for dataset ogbg-molhiv.\n",
      "Evaluating hyperparameter configuration 2 for dataset ogbg-molhiv.\n",
      "Repeat 0 for hyperparameter configuration 2 already evaluated for dataset ogbg-molhiv.\n",
      "Repeat 1 for hyperparameter configuration 2 already evaluated for dataset ogbg-molhiv.\n",
      "Repeat 2 for hyperparameter configuration 2 already evaluated for dataset ogbg-molhiv.\n"
     ]
    }
   ],
   "source": [
    "gridS.train_and_evaluate(small_sample, 'ogbg-molhiv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating hyperparameter configuration 0 for dataset ogbg-molpcba.\n",
      "Repeat 0 for hyperparameter configuration 0 already evaluated for dataset ogbg-molpcba.\n",
      "Repeat 1 for hyperparameter configuration 0 already evaluated for dataset ogbg-molpcba.\n",
      "Repeat 2 for hyperparameter configuration 0 already evaluated for dataset ogbg-molpcba.\n",
      "Evaluating hyperparameter configuration 1 for dataset ogbg-molpcba.\n",
      "Repeat 0 for hyperparameter configuration 1 already evaluated for dataset ogbg-molpcba.\n",
      "Repeat 1 for hyperparameter configuration 1 already evaluated for dataset ogbg-molpcba.\n",
      "Repeat 2 for hyperparameter configuration 1 already evaluated for dataset ogbg-molpcba.\n",
      "Evaluating hyperparameter configuration 2 for dataset ogbg-molpcba.\n",
      "Repeat 0 for hyperparameter configuration 2 already evaluated for dataset ogbg-molpcba.\n",
      "Repeat 1 for hyperparameter configuration 2 already evaluated for dataset ogbg-molpcba.\n",
      "Repeat 2 for hyperparameter configuration 2 already evaluated for dataset ogbg-molpcba.\n"
     ]
    }
   ],
   "source": [
    "gridS.train_and_evaluate(small_sample, 'ogbg-molpcba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating hyperparameter configuration 0 for dataset ogbg-molhiv.\n",
      "138/138 [==============================] - 3s 14ms/step - loss: 0.1471 - auc: 0.5000 - binary_accuracy: 0.9684 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.1418 - val_auc: 0.5000 - val_binary_accuracy: 0.9684 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "138/138 [==============================] - 1s 5ms/step - loss: 0.1398 - auc: 0.5000 - binary_accuracy: 0.9684 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "138/138 [==============================] - 1s 4ms/step\n",
      "138/138 [==============================] - 4s 11ms/step - loss: 0.9391 - auc: 0.5171 - binary_accuracy: 0.7717 - precision: 0.0398 - recall: 0.2692 - val_loss: 0.3184 - val_auc: 0.4985 - val_binary_accuracy: 0.9679 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "138/138 [==============================] - 1s 4ms/step - loss: 0.3171 - auc: 0.4995 - binary_accuracy: 0.9684 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "138/138 [==============================] - 1s 3ms/step\n",
      "138/138 [==============================] - 3s 11ms/step - loss: 0.1443 - auc: 0.4997 - binary_accuracy: 0.9684 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.1447 - val_auc: 0.5000 - val_binary_accuracy: 0.9684 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "138/138 [==============================] - 1s 3ms/step - loss: 0.1442 - auc: 0.5000 - binary_accuracy: 0.9684 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "138/138 [==============================] - 1s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "gridS.train_and_evaluate(small_sample, 'ogbg-molhiv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"hyperparams\": {\"activation\": \"relu\", \"convo_type\": \"gin\", \"learning_rate\": 0.0001, \"num_layers\": 1, \"optimizer\": \"Adam\", \"probability\": 0.3, \"regularization\": \"DropOut\", \"units\": 32}, \"test_loss\": 0.13981470465660095, \"test_acc\": [0.5, 0.9683929085731506, 0.0, 0.0], \"test_rocauc\": 0.4990922961045984, \"training_history\": {\"loss\": [0.147053524851799], \"auc\": [0.5], \"binary_accuracy\": [0.9683929085731506], \"precision\": [0.0], \"recall\": [0.0], \"val_loss\": [0.1418473869562149], \"val_auc\": [0.5], \"val_binary_accuracy\": [0.9683929085731506], \"val_precision\": [0.0], \"val_recall\": [0.0]}, \"train_loss\": 0.147053524851799, \"val_loss\": 0.1418473869562149}\n"
     ]
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n",
    "type_dir = type(current_dir)\n",
    "contents = os.listdir()\n",
    "with open('/home/olga/GraphNeuralNetwork/ogbg-molhiv/hpconfig_0/repeat_0.json', 'r') as file: \n",
    "    data = file.read() \n",
    "    print(data)\n",
    "    file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<posix.ScandirIterator at 0x7facedb95450>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contents_new = os.scandir() \n",
    "contents_new \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workplan.md\n",
      "gridSearch.py\n",
      ".gitignore\n",
      "convo.py\n",
      "gridS.py\n",
      "__pycache__\n",
      "ogbg-molhiv\n",
      "csv.ipynb\n",
      "batching.py\n",
      "metrics.py\n",
      "readme.md\n",
      "dataset\n",
      "modularized.py\n",
      "ogbg-molpcba\n",
      "eval.py\n",
      "prototype.py\n",
      "gin.py\n",
      ".editorconfig\n",
      ".git\n",
      "poolingL.py\n",
      "mad.py\n",
      "experiments.py\n",
      "test.ipynb\n",
      "convL.py\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "posix.ScandirIterator"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with os.scandir('/home/olga/GraphNeuralNetwork') as entries:\n",
    "    for entry in entries: \n",
    "        print(entry.name)\n",
    "\n",
    "type(entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotADirectoryError",
     "evalue": "[Errno 20] Not a directory: '/home/olga/GraphNeuralNetwork/workplan.md'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotADirectoryError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 72\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[39m# Usage example\u001b[39;00m\n\u001b[1;32m     71\u001b[0m experiment_results_dir \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/home/olga/GraphNeuralNetwork\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m---> 72\u001b[0m find_winner_hyperparams(experiment_results_dir)\n",
      "Cell \u001b[0;32mIn[13], line 15\u001b[0m, in \u001b[0;36mfind_winner_hyperparams\u001b[0;34m(experiment_results_dir)\u001b[0m\n\u001b[1;32m     12\u001b[0m dataset_dir \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(experiment_results_dir, dataset_folder)\n\u001b[1;32m     14\u001b[0m \u001b[39m# Get the list of hyperparameter configuration folders\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m hpconfig_folders \u001b[39m=\u001b[39m [folder \u001b[39mfor\u001b[39;00m folder \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39;49mlistdir(\n\u001b[1;32m     16\u001b[0m     dataset_dir) \u001b[39mif\u001b[39;00m folder\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39mhpconfig_\u001b[39m\u001b[39m\"\u001b[39m)]\n\u001b[1;32m     18\u001b[0m \u001b[39mfor\u001b[39;00m hpconfig_folder \u001b[39min\u001b[39;00m hpconfig_folders:\n\u001b[1;32m     19\u001b[0m     hpconfig_dir \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(dataset_dir, hpconfig_folder)\n",
      "\u001b[0;31mNotADirectoryError\u001b[0m: [Errno 20] Not a directory: '/home/olga/GraphNeuralNetwork/workplan.md'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def find_winner_hyperparams(experiment_results_dir):\n",
    "    # Get the list of dataset folders\n",
    "    dataset_folders = os.listdir(experiment_results_dir)\n",
    "\n",
    "    for dataset_folder in dataset_folders:\n",
    "        dataset_dir = os.path.join(experiment_results_dir, dataset_folder)\n",
    "\n",
    "        # Get the list of hyperparameter configuration folders\n",
    "        hpconfig_folders = [folder for folder in os.listdir(\n",
    "            dataset_dir) if folder.startswith(\"hpconfig_\")]\n",
    "\n",
    "        for hpconfig_folder in hpconfig_folders:\n",
    "            hpconfig_dir = os.path.join(dataset_dir, hpconfig_folder)\n",
    "\n",
    "            # Get the list of repeat JSON files\n",
    "            repeat_files = [file for file in os.listdir(\n",
    "                hpconfig_dir) if file.endswith(\".json\")]\n",
    "\n",
    "            if repeat_files:\n",
    "                # Load the repeat files and find the winner hyperparameter configuration\n",
    "                winner_loss = float(\"inf\")\n",
    "                winner_config = None\n",
    "\n",
    "                for repeat_file in repeat_files:\n",
    "                    repeat_filepath = os.path.join(hpconfig_dir, repeat_file)\n",
    "\n",
    "                    with open(repeat_filepath) as f:\n",
    "                        repeat_data = json.load(f)\n",
    "                        repeat_loss = repeat_data[\"val_loss\"]\n",
    "\n",
    "                        if repeat_loss < winner_loss:\n",
    "                            winner_loss = repeat_loss\n",
    "                            winner_config = repeat_data[\"hyperparams\"]\n",
    "\n",
    "                if winner_config:\n",
    "                    # Calculate the average val-loss and standard deviation of the winner configuration\n",
    "                    val_losses = []\n",
    "\n",
    "                    for repeat_file in repeat_files:\n",
    "                        repeat_filepath = os.path.join(\n",
    "                            hpconfig_dir, repeat_file)\n",
    "\n",
    "                        with open(repeat_filepath) as f:\n",
    "                            repeat_data = json.load(f)\n",
    "\n",
    "                            if repeat_data[\"hyperparams\"] == winner_config:\n",
    "                                val_losses.append(repeat_data[\"val_loss\"])\n",
    "\n",
    "                    avg_val_loss = np.mean(val_losses)\n",
    "                    std_val_loss = np.std(val_losses)\n",
    "\n",
    "                    # Write the winner configuration, average val-loss, and standard deviation to a CSV file\n",
    "                    csv_filename = os.path.join(\n",
    "                        dataset_dir, f\"winner_{hpconfig_folder}.csv\")\n",
    "\n",
    "                    with open(csv_filename, mode='w', newline='') as csvfile:\n",
    "                        writer = csv.writer(csvfile)\n",
    "                        writer.writerow(\n",
    "                            [\"Hyperparams\", \"Average Val-Loss\", \"Standard Deviation\"])\n",
    "                        writer.writerow(\n",
    "                            [json.dumps(winner_config), avg_val_loss, std_val_loss])\n",
    "\n",
    "\n",
    "# Usage example\n",
    "experiment_results_dir = '/home/olga/GraphNeuralNetwork'\n",
    "find_winner_hyperparams(experiment_results_dir)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
